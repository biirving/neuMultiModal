{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88a516b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/Desktop/ml/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 716/716 [00:00<00:00, 1.38MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/benjamin/.cache/huggingface/datasets/Multimodal-Fatima___parquet/Multimodal-Fatima--Hatefulmemes_train-cf2bb543f5aaeaee/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 437M/437M [00:04<00:00, 91.0MB/s]\n",
      "Downloading data: 100%|██████████| 441M/441M [00:10<00:00, 43.2MB/s]\n",
      "Downloading data: 100%|██████████| 432M/432M [00:05<00:00, 79.7MB/s]\n",
      "Downloading data: 100%|██████████| 440M/440M [00:05<00:00, 76.5MB/s]\n",
      "Downloading data: 100%|██████████| 430M/430M [00:06<00:00, 70.9MB/s]\n",
      "Downloading data: 100%|██████████| 433M/433M [00:05<00:00, 77.2MB/s]\n",
      "Downloading data: 100%|██████████| 442M/442M [00:07<00:00, 58.3MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:49<00:00, 49.15s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 628.08it/s]\n",
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/benjamin/.cache/huggingface/datasets/Multimodal-Fatima___parquet/Multimodal-Fatima--Hatefulmemes_train-cf2bb543f5aaeaee/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 299.83it/s]\n",
      "Downloading readme: 100%|██████████| 711/711 [00:00<00:00, 890kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/benjamin/.cache/huggingface/datasets/Multimodal-Fatima___parquet/Multimodal-Fatima--Hatefulmemes_test-c1760e361ffe8410/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 362M/362M [00:06<00:00, 56.9MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:06<00:00,  6.84s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1854.25it/s]\n",
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/benjamin/.cache/huggingface/datasets/Multimodal-Fatima___parquet/Multimodal-Fatima--Hatefulmemes_test-c1760e361ffe8410/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1021.26it/s]\n",
      "Downloading: 100%|██████████| 631/631 [00:00<00:00, 1.05MB/s]\n",
      "Downloading: 100%|██████████| 448M/448M [00:06<00:00, 68.5MB/s] \n"
     ]
    }
   ],
   "source": [
    "# generalizeable testing script\n",
    "# using the HuggingFace Library\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModel\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "from transformers import BeitFeatureExtractor, BeitForImageClassification\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://huggingface.co\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "@article{DBLP:journals/corr/abs-2005-04790,\n",
    "  author    = {Douwe Kiela and\n",
    "               Hamed Firooz and\n",
    "               Aravind Mohan and\n",
    "               Vedanuj Goswami and\n",
    "               Amanpreet Singh and\n",
    "               Pratik Ringshia and\n",
    "               Davide Testuggine},\n",
    "  title     = {The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes},\n",
    "  journal   = {CoRR},\n",
    "  volume    = {abs/2005.04790},\n",
    "  year      = {2020},\n",
    "  url       = {https://arxiv.org/abs/2005.04790},\n",
    "  eprinttype = {arXiv},\n",
    "  eprint    = {2005.04790},\n",
    "  timestamp = {Thu, 14 May 2020 16:56:02 +0200},\n",
    "  biburl    = {https://dblp.org/rec/journals/corr/abs-2005-04790.bib},\n",
    "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "train_data = load_dataset(\"Multimodal-Fatima/Hatefulmemes_train\")\n",
    "test_data = load_dataset(\"Multimodal-Fatima/Hatefulmemes_test\")\n",
    "\n",
    "\n",
    "# transform the image for input\n",
    "my_transforms = transforms.Compose([\n",
    "transforms.ToPILImage(),                                                                                                                                                                                                   \n",
    "transforms.Resize((224, 224)),                                                                                                  \n",
    "transforms.ToTensor()                                                                                                           \n",
    "])\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForPreTraining\n",
    "model = AutoModelForPreTraining.from_pretrained(\"uclanlp/visualbert-vqa-coco-pre\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b2b4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Features, ClassLabel, Array3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a67756",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Features({ \n",
    "  'label': ClassLabel(num_classes=2), \n",
    "  'image': Image(decode=True, id=None), \n",
    "  'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)), \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transform the image for input\n",
    "my_transforms = transforms.Compose([\n",
    "transforms.ToPILImage(),                                                                                                                                                                                                   \n",
    "transforms.Resize((224, 224)),                                                                                                  \n",
    "transforms.ToTensor()                                                                                                           \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e73e9e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=283x400 at 0x7FA9F7F0FB20>, 'text': 'handjobs sold seperately', 'label': 1, 'id': 0, 'clip_tags_ViT_L_14': ['quadriplegic', 'prosthetist', 'amputated arm', 'phantom limb', 'phantom limb syndrome'], 'LLM_Description_gpt3_downstream_tasks_ViT_L_14': ['lack of limbs', 'sleeveless or with long sleeves', 'a robotic arm', 'a support or base to which the arm or frame is attached', 'two curved arms that come to a point'], 'blip_caption': 'a woman with long blonde hair'}\n"
     ]
    }
   ],
   "source": [
    "image_0 = test_data['test'][0]['image']\n",
    "print(image_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "42b2ed5eaf5b0df0635e21b6d1cbf29a12944d3072d5b8f2a0ee60d1c4610543"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
